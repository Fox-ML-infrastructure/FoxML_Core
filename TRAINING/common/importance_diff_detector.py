"""
Copyright (c) 2025-2026 Fox ML Infrastructure LLC

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Affero General Public License as published
by the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Affero General Public License for more details.

You should have received a copy of the GNU Affero General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""

"""
Feature Importance Diff Detector

Compares feature importances between models trained with all features
vs. models trained with only "safe" features to detect potential leakage.

If a feature has high importance in the full model but low in the safe model,
it's suspicious and may be encoding future information.
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class SuspiciousFeature:
    """A feature flagged as potentially leaky based on importance diff."""
    feature_name: str
    importance_full: float
    importance_safe: float
    importance_diff: float
    relative_diff: float  # diff / max(importance_full, 1e-6)
    reason: str


class ImportanceDiffDetector:
    """
    Detects potential leakage by comparing feature importances.
    
    Compares models trained with:
    - Full feature set (may include leaky features)
    - Safe feature set (only registry-allowed features)
    
    Features with high importance in full but low in safe are flagged as suspicious.
    """
    
    def __init__(
        self,
        diff_threshold: float = 0.1,
        relative_diff_threshold: float = 0.5,
        min_importance_full: float = 0.01
    ):
        """
        Initialize importance diff detector.
        
        Args:
            diff_threshold: Absolute difference threshold (importance_full - importance_safe)
            relative_diff_threshold: Relative difference threshold (diff / importance_full)
            min_importance_full: Minimum importance in full model to consider (filters noise)
        """
        self.diff_threshold = diff_threshold
        self.relative_diff_threshold = relative_diff_threshold
        self.min_importance_full = min_importance_full
    
    def get_feature_importance(
        self,
        model: Any,
        feature_names: List[str],
        importance_method: str = 'auto'
    ) -> pd.Series:
        """
        Extract feature importance from a model.
        
        Args:
            model: Trained model
            feature_names: List of feature names
            importance_method: Method to use ('auto', 'native', 'shap', 'permutation')
        
        Returns:
            Series with feature names as index and importance as values
        """
        # Try native importance first
        if importance_method in ('auto', 'native'):
            try:
                if hasattr(model, 'feature_importances_'):
                    # sklearn models
                    importance = model.feature_importances_
                elif hasattr(model, 'feature_importance'):
                    # LightGBM
                    importance = model.feature_importance(importance_type='gain')
                elif hasattr(model, 'get_feature_importance'):
                    # CatBoost
                    importance = model.get_feature_importance()
                elif hasattr(model, 'coef_'):
                    # Linear models
                    importance = np.abs(model.coef_)
                    if len(importance.shape) > 1:
                        importance = importance[0]  # Take first row for multi-output
                elif hasattr(model, 'get_score'):
                    # XGBoost native API
                    score_dict = model.get_score(importance_type='gain')
                    importance = np.array([score_dict.get(f, 0.0) for f in feature_names])
                else:
                    raise ValueError("Model does not have native feature importance")
                
                # Ensure importance matches feature_names length
                if len(importance) != len(feature_names):
                    logger.warning(f"Importance length ({len(importance)}) doesn't match features ({len(feature_names)})")
                    # Pad or truncate if needed
                    if len(importance) < len(feature_names):
                        importance = np.pad(importance, (0, len(feature_names) - len(importance)), 'constant')
                    else:
                        importance = importance[:len(feature_names)]
                
                # Normalize to 0-1 range
                if importance.max() > 0:
                    importance = importance / importance.max()
                
                return pd.Series(importance, index=feature_names)
            
            except Exception as e:
                logger.debug(f"Native importance extraction failed: {e}")
                if importance_method == 'native':
                    raise
        
        # Fallback: return zero importance
        logger.warning(f"Could not extract importance from model, returning zeros")
        return pd.Series(0.0, index=feature_names)
    
    def detect_suspicious_features(
        self,
        model_full: Any,
        model_safe: Any,
        feature_names_full: List[str],
        feature_names_safe: List[str],
        importance_method: str = 'auto'
    ) -> List[SuspiciousFeature]:
        """
        Compare feature importances to detect potentially leaky features.
        
        Args:
            model_full: Model trained with all features (including potentially leaky)
            model_safe: Model trained with only safe features (registry-validated)
            feature_names_full: Feature names for full model
            feature_names_safe: Feature names for safe model
            importance_method: Method to extract importance
        
        Returns:
            List of SuspiciousFeature objects
        """
        # Extract importances
        importance_full = self.get_feature_importance(model_full, feature_names_full, importance_method)
        importance_safe = self.get_feature_importance(model_safe, feature_names_safe, importance_method)
        
        # Create index for safe features (may be subset of full)
        importance_safe_indexed = pd.Series(0.0, index=feature_names_full)
        for feat in feature_names_safe:
            if feat in importance_safe.index:
                importance_safe_indexed[feat] = importance_safe[feat]
        
        # Calculate differences
        suspicious = []
        
        for feat in feature_names_full:
            imp_full = importance_full.get(feat, 0.0)
            imp_safe = importance_safe_indexed.get(feat, 0.0)
            
            # Skip if importance in full model is too low (noise)
            if imp_full < self.min_importance_full:
                continue
            
            # Calculate absolute and relative differences
            diff = imp_full - imp_safe
            relative_diff = diff / max(imp_full, 1e-6)
            
            # Check thresholds
            is_suspicious = (
                diff > self.diff_threshold or
                relative_diff > self.relative_diff_threshold
            )
            
            if is_suspicious:
                reason = []
                if diff > self.diff_threshold:
                    reason.append(f"absolute_diff={diff:.3f} > {self.diff_threshold}")
                if relative_diff > self.relative_diff_threshold:
                    reason.append(f"relative_diff={relative_diff:.1%} > {self.relative_diff_threshold:.1%}")
                
                suspicious.append(SuspiciousFeature(
                    feature_name=feat,
                    importance_full=float(imp_full),
                    importance_safe=float(imp_safe),
                    importance_diff=float(diff),
                    relative_diff=float(relative_diff),
                    reason="; ".join(reason)
                ))
        
        # Sort by difference (most suspicious first)
        suspicious.sort(key=lambda x: x.importance_diff, reverse=True)
        
        return suspicious
    
    def detect_and_report(
        self,
        model_full: Any,
        model_safe: Any,
        feature_names_full: List[str],
        feature_names_safe: List[str],
        importance_method: str = 'auto',
        top_n: int = 10
    ) -> Dict[str, Any]:
        """
        Detect suspicious features and generate a report.
        
        Args:
            model_full: Model trained with all features
            model_safe: Model trained with only safe features
            feature_names_full: Feature names for full model
            feature_names_safe: Feature names for safe model
            importance_method: Method to extract importance
            top_n: Number of top suspicious features to include in summary
        
        Returns:
            Dictionary with detection results and summary
        """
        suspicious = self.detect_suspicious_features(
            model_full, model_safe,
            feature_names_full, feature_names_safe,
            importance_method
        )
        
        # Generate report
        if suspicious:
            logger.warning(
                f"ðŸš¨ SUSPECTED LEAKS: {len(suspicious)} features have high importance "
                f"in full model but low in safe model"
            )
            
            # Log top N suspicious features
            for i, feat in enumerate(suspicious[:top_n], 1):
                logger.warning(
                    f"  {i}. {feat.feature_name}: "
                    f"full={feat.importance_full:.3f}, "
                    f"safe={feat.importance_safe:.3f}, "
                    f"diff={feat.importance_diff:.3f} ({feat.reason})"
                )
            
            if len(suspicious) > top_n:
                logger.warning(f"  ... and {len(suspicious) - top_n} more suspicious features")
        else:
            logger.info("âœ… No suspicious features detected (importance diff test passed)")
        
        return {
            'n_suspicious': len(suspicious),
            'suspicious_features': [
                {
                    'feature_name': f.feature_name,
                    'importance_full': f.importance_full,
                    'importance_safe': f.importance_safe,
                    'importance_diff': f.importance_diff,
                    'relative_diff': f.relative_diff,
                    'reason': f.reason
                }
                for f in suspicious
            ],
            'top_n': top_n
        }

