# Preprocessing Configuration
# Settings for data preprocessing, imputation, scaling, and validation

preprocessing:
  # Imputation
  imputation:
    strategy: "median"  # "median", "mean", "most_frequent", or "constant"
    fill_value: 0.0  # Value for "constant" strategy
    handle_nan: true  # Enable NaN handling
  
  # Scaling
  scaling:
    method: "standard"  # "standard" (StandardScaler), "minmax" (MinMaxScaler), or null
    with_mean: true  # For StandardScaler
    with_std: true  # For StandardScaler
    feature_range: [0, 1]  # For MinMaxScaler
  
  # Feature Selection
  feature_selection:
    n_features: 50  # Number of features to select
    min_importance: 0.001  # Minimum feature importance threshold
    method: "mutual_info"  # "mutual_info", "f_test", or "chi2"
  
  # Validation Splits
  validation:
    test_size: 0.2  # 20% test split (default)
    train_ratio: 0.8  # 80% training ratio (for time-aware splits)
    val_ratio: 0.15  # 15% validation ratio (for sequential datasets)
    test_ratio: 0.15  # 15% test ratio (for sequential datasets)
    random_state: 42  # Random state for splits
    shuffle: true  # Shuffle data before splitting
    early_stopping_rounds: 50  # Default early stopping rounds
  
  # NaN Handling
  nan_handling:
    nan_ratio_threshold: 0.1  # 10% NaN threshold for warnings
    drop_high_nan: false  # Drop features/rows with high NaN ratio
    max_nan_ratio: 0.5  # Maximum NaN ratio before dropping
  
  # Data Validation
  validation_checks:
    check_nan: true  # Check for NaN values
    check_inf: true  # Check for infinite values
    check_leakage: true  # Check for data leakage
    check_duplicates: false  # Check for duplicate rows
    max_sequence_gap: 300  # Maximum gap between timestamps (seconds)
  
  # Feature Engineering
  feature_engineering:
    create_interactions: false  # Create feature interactions
    polynomial_features: false  # Create polynomial features
    degree: 2  # Polynomial degree (if enabled)
  
  # Feature Pruning
  feature_pruning:
    n_estimators: 50  # Number of estimators for quick pruning models
    max_depth: 5  # Maximum depth for pruning models (shallow for speed)
    learning_rate: 0.1  # Learning rate for pruning models
    cumulative_threshold: 0.0001  # Cumulative importance threshold (0.01%)
    min_features: 50  # Minimum features to keep after pruning

