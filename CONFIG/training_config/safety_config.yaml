# Safety and Numerical Stability Configuration
# Settings for numerical guards, clipping, and safety thresholds

safety:
  # Feature Clipping
  feature_clipping:
    enabled: true
    clip_value: 1000.0  # Clip features to [-1000, 1000]
    log_clipped: false  # Log when features are clipped
  
  # Target Capping
  target_capping:
    enabled: true
    cap_sigma: 15.0  # Cap targets using 15 MAD (median absolute deviation)
    log_capped: false  # Log when targets are capped
  
  # Numerical Stability
  numerical:
    safe_exp_bounds:
      lo: -40.0  # Lower bound for safe exponential
      hi: 40.0  # Upper bound for safe exponential
    
    numpy_error_handling:
      over: "warn"  # Overflow handling: "warn", "raise", "ignore"
      invalid: "warn"  # Invalid value handling
      divide: "warn"  # Division by zero handling
      under: "ignore"  # Underflow handling
  
  # Gradient Clipping
  gradient_clipping:
    enabled: true
    clipnorm: 1.0  # Gradient norm clipping (TensorFlow/Keras)
    max_norm: 1.0  # Maximum gradient norm (PyTorch)
  
  # Model Output Validation
  validation:
    check_predictions: true  # Check predictions for NaN/Inf
    check_gradients: false  # Check gradients for NaN/Inf (expensive)
    log_anomalies: true  # Log when anomalies are detected
  
  # Safety Guards
  guards:
    min_history_bars: 120  # Minimum history bars before feature use
    max_na_fraction: 0.05  # Maximum NaN fraction (5%)
    hold_on_nan: true  # Return HOLD action on NaN in predictions
  
  # Leakage Detection & Auto-Fix Thresholds
  leakage_detection:
    # Auto-fixer triggers when scores exceed these thresholds
    auto_fix_thresholds:
      cv_score: 0.99  # Cross-validation score threshold (0.99 = 99%)
      training_accuracy: 0.999  # Training accuracy threshold (0.999 = 99.9%)
      training_r2: 0.999  # Training R² threshold for regression (0.999 = 99.9%)
      perfect_correlation: 0.999  # Perfect correlation threshold (0.999 = 99.9%)
    
    # Minimum confidence for auto-fixer to apply fixes (0.0 to 1.0)
    auto_fix_min_confidence: 0.8  # Only auto-fix leaks with >= 80% confidence
    
    # Maximum number of features to auto-fix per run (prevents overly aggressive fixes)
    auto_fix_max_features_per_run: 20  # Limit auto-fixes to top N most confident detections
    
    # Enable/disable auto-fixer
    auto_fix_enabled: true  # Set to false to disable automatic leakage fixing
    
    # Auto-rerun after fixing leaks
    auto_rerun:
      enabled: true  # Enable automatic rerun of targets after auto-fix
      max_reruns: 3  # Maximum number of reruns per target (default: 3)
      rerun_on_perfect_train_acc: true  # Rerun if perfect training accuracy detected
      rerun_on_high_auc_only: false  # Rerun on high AUC alone (default: false, only rerun on perfect train acc)
    
    # Pre-training leak scan thresholds
    pre_scan:
      min_match: 0.999  # Minimum match ratio for binary classification (99.9%)
      min_corr: 0.999  # Minimum correlation for regression (99.9%)
      min_valid_pairs: 10  # Minimum valid pairs needed for correlation check
    
    # Feature count requirements for ranking
    ranking:
      min_features_required: 2  # Minimum features needed after filtering (for ranking)
      min_features_for_model: 3  # Minimum features needed for meaningful model training
      min_features_after_leak_removal: 2  # Minimum features after removing leaky features
      # Maximum feature lookback cap for ranking mode (prevents 1440m purge/embargo inflation)
      # Set to null to disable cap (use actual feature lookback)
      # Set to number (e.g., 240) to cap lookback at 4 hours (excludes 1D+ lookback features)
      ranking_mode_max_lookback_minutes: null  # null = no cap, or set to e.g., 240 for 4-hour cap
    
  # Purge/embargo configuration
  temporal:
    purge_include_feature_lookback: true  # If true, purge = max(horizon+buffer, feature_lookback_max * 1.01)
    # If false, purge = horizon+buffer only (assumes features are strictly causal, only use past data)
    # When enabled, automatically increases purge to cover longest feature lookback window + 1% safety buffer
    default_purge_minutes: 1500.0  # NUCLEAR TEST: 24-hour purge to test if leak is in features or target
    # TEMPORARY: Set to 1500 (24 hours) to test if score drops (feature leak) or stays high (target leak/repainting)
    # If score drops to ~0.53 → feature leak (fixable)
    # If score stays at ~0.99 → target leak (delete target, it's repainting)
    # Set purge_include_feature_lookback to false if feature lookback is killing sample efficiency 
    # and you're confident features are strictly causal (only use past data)
  
  # Active Sanitization (Ghost Buster)
  # Automatically quarantines features with excessive lookback before training starts
  # This prevents "ghost feature" discrepancies where audit and auto-fix see different lookback values
  active_sanitization:
    enabled: true  # Enable active sanitization (automatically quarantine problematic features)
    max_safe_lookback_minutes: 240.0  # Maximum safe lookback in minutes (default: 4 hours)
    # Features with lookback > this threshold will be automatically quarantined
    # Set to null to disable lookback-based quarantine (only use pattern-based)
    
    # Pattern-based quarantine (more aggressive - quarantines by naming patterns)
    pattern_quarantine:
      enabled: false  # Default: disabled (more aggressive, use with caution)
      patterns: []  # List of regex patterns to match (e.g., [".*_1d$", ".*daily.*"])
      # If enabled, features matching these patterns will be quarantined regardless of computed lookback
  
  # Reproducibility Tracking Thresholds
  reproducibility:
    enabled: true
    # Cohort-aware reproducibility: organize runs by sample size, symbols, date range, config
    # DEFAULT: true (cohort-aware mode is the default and recommended)
    # Set to false only if you need the legacy flat-file structure
    cohort_aware: true  # Enable cohort-aware tracking (organizes by cohort, only compares within cohorts)
    n_ratio_threshold: 0.90  # Min ratio (min/max) for comparability (0.90 = 90% overlap required)
    cohort_config_keys:      # Keys to include in cohort hash (identifies different cohorts)
      - min_cs
      - max_cs_samples
      - leakage_filter_version
      - universe_id
    # Tolerance bands: STABLE (within noise) / DRIFTING (small changes) / DIVERGED (real issues)
    thresholds:
      # ROC-AUC / R² / primary score thresholds
      roc_auc:
        abs: 0.005      # 0.5 AUC points absolute difference (effect size threshold)
        rel: 0.02       # 2% relative difference (effect size threshold)
        z_score: 2.0    # z-score threshold for DIVERGED (requires ~95% confidence, i.e., statistically significant)
      # Composite score thresholds
      composite:
        abs: 0.02       # 0.02 in composite space (effect size threshold)
        rel: 0.05       # 5% relative difference (effect size threshold)
        z_score: 2.0    # z-score threshold for DIVERGED (requires ~95% confidence)
      # Importance thresholds
      importance:
        abs: 0.05       # 0.05 absolute difference (effect size threshold)
        rel: 0.20       # 20% relative difference (importance is more variable)
        z_score: 2.5    # z-score threshold for DIVERGED (importance is more variable, so require higher confidence)
    # Classification rules: differences must be within BOTH abs AND rel thresholds for STABLE
    # DRIFTING: within 2x thresholds, DIVERGED: exceeds 2x thresholds
    use_z_score: true   # If true, use z-score (|Δ| / σ) when std_score is available
  
  # Leakage warning thresholds (for detect_leakage function)
    warning_thresholds:
      classification:
        high: 0.90  # ROC-AUC/Accuracy > 0.90 is suspicious
        very_high: 0.95  # ROC-AUC/Accuracy > 0.95 is extremely suspicious
      regression:
        forward_return:
          high: 0.50  # R² > 0.50 is suspicious for forward returns
          very_high: 0.60  # R² > 0.60 is extremely suspicious
        barrier:
          high: 0.70  # R² > 0.70 is suspicious for barrier targets
          very_high: 0.80  # R² > 0.80 is extremely suspicious
    
    # Model-specific leakage alert thresholds
    model_alerts:
      suspicious_score: 0.99  # Score >= 0.99 triggers leakage alert (for LightGBM, RF, etc.)
    
    # Importance thresholds
    importance:
      single_feature_threshold: 0.50  # Flag if single feature has >50% importance
      high_importance_threshold: 0.30  # Threshold for high importance detection
    
    # Model evaluation thresholds
    model_evaluation:
      # Binary classification threshold
      binary_classification_threshold: 0.5  # Probability threshold for binary classification
      # Consistency check thresholds
      composite_score_high_threshold: 0.5  # High composite score threshold
      regression_score_low_threshold: 0.2  # Low score threshold for regression
      classification_score_low_threshold: 0.6  # Low score threshold for classification
      importance_high_threshold: 0.7  # High importance threshold
      regression_score_very_low_threshold: 0.1  # Very low score threshold for regression
      classification_score_very_low_threshold: 0.5  # Very low score threshold for classification
      # Feature pruning threshold
      feature_count_pruning_threshold: 100  # Only prune if feature count exceeds this
      # Interval detection tolerance
      interval_detection_tolerance: 0.2  # 20% tolerance for interval detection
    
    # Leakage Sentinel Thresholds
    leakage_sentinels:
      shifted_target_threshold: 0.5  # If model score > this on shifted target, flag as leaky
      symbol_holdout_train_threshold: 0.9  # If train score > this, flag for investigation
      symbol_holdout_test_threshold: 0.3  # If test score < this (with high train), flag as leaky
      randomized_time_threshold: 0.5  # If model score > this on time-shuffled data, flag as leaky
    
    # Auto-Fixer Settings
    auto_fixer:
      perfect_score_threshold: 0.99  # Train score >= this indicates leakage
      min_confidence: 0.7  # Minimum confidence to auto-fix (0.0 to 1.0)
      max_backups_per_target: 20  # Maximum backups to keep per target
      symbol_holdout_test_size: 0.2  # Test size for symbol holdout split
    
    # Feature Importance Stability Tracking
    feature_importance:
      # Automatically analyze stability after saving snapshots
      auto_analyze_stability: true  # Set to false to disable automatic analysis
      
      # Stability thresholds for warnings
      stability_thresholds:
        min_top_k_overlap: 0.7  # Warn if top-K overlap < 0.7 (Jaccard similarity)
        min_kendall_tau: 0.6     # Warn if Kendall tau < 0.6 (rank correlation)
        top_k: 20                # Number of top features to analyze (default: 20)
        min_snapshots: 2         # Minimum snapshots required for analysis (default: 2)

