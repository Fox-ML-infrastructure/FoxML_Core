# Task-Specific Metrics Schema
# Defines which metrics are valid for each task type
#
# Keys are actual JSON field names persisted in metrics.json (not display names)
# Schema loaded once and cached via @lru_cache

regression:
  # Distribution stats for continuous targets
  target_stats:
    - y_mean
    - y_std
    - y_min
    - y_max
    - y_finite_pct
  # Fields that should NEVER appear for regression
  exclude:
    - pos_rate
    - class_balance
    - precision
    - recall
    - f1

binary_classification:
  # Class balance stats for binary targets
  target_stats:
    - pos_rate        # Fraction of samples with pos_label
    - class_balance   # Dict of {label: count}
  # Default positive label (override in TaskSpec if needed)
  pos_label: 1
  # Fields that should NEVER appear for binary classification
  exclude:
    - y_mean
    - y_std
    - y_min
    - y_max
    - r2
    - rmse
    - mae

multiclass_classification:
  # Class balance stats for multiclass targets
  target_stats:
    - class_balance   # Dict of {label: count}
    - n_classes       # Number of unique classes
  # pos_rate is NOT emitted for multiclass (use class_balance instead)
  exclude:
    - pos_rate
    - y_mean
    - y_std
    - y_min
    - y_max
    - r2
    - rmse
    - mae

# =============================================================================
# Canonical Metric Naming
# =============================================================================
# Format: <metric_base>__<view>__<aggregation>
# - view: cs (cross-sectional) or sym (symbol-specific)
# - aggregation: mean, std, pooled
#
# This eliminates the overloaded "auc" field that stored different metrics
# depending on task type (R2 for regression, ROC-AUC for binary, etc.)

canonical_names:
  regression:
    cross_sectional:
      # Rank IC (Spearman correlation per timestamp, averaged over time)
      primary: spearman_ic__cs__mean
      std: spearman_ic__cs__std
      secondary:
        - r2__cs__pooled
        - mae__cs__pooled
    symbol_specific:
      # R2 per symbol over time, averaged across symbols
      primary: r2__sym__mean
      std: r2__sym__std
      secondary:
        - spearman_corr__sym__mean
        - rmse__sym__mean
  
  binary_classification:
    cross_sectional:
      # ROC-AUC per timestamp, averaged over time
      primary: roc_auc__cs__mean
      std: roc_auc__cs__std
      secondary:
        - pr_auc__cs__mean
        - log_loss__cs__mean
    symbol_specific:
      # ROC-AUC per symbol over time, averaged across symbols
      primary: roc_auc__sym__mean
      std: roc_auc__sym__std
      secondary:
        - pr_auc__sym__mean
  
  multiclass_classification:
    cross_sectional:
      primary: accuracy__cs__mean
      std: accuracy__cs__std
      secondary:
        - macro_f1__cs__mean
    symbol_specific:
      primary: accuracy__sym__mean
      std: accuracy__sym__std

# =============================================================================
# Scoring Configuration (P1 - Phase 3.1)
# =============================================================================
# Versioned parameters for composite score calculation.
# Hash of this section becomes scoring_signature for reproducibility.
#
# Phase 3.1 fixes:
# - SE-based stability (not std-based) for cross-family comparability
# - Skill-gated composite (skill * quality, not additive)
# - Classification centering (AUC-excess, not raw AUC)
# - Deterministic invalid slice filtering

scoring:
  version: "1.1"  # Bump for Phase 3.1 fixes
  
  # Skill normalization via t-stat
  # skill_tstat = mean / (std / sqrt(n)) = mean / se
  # skill_score_01 = sigmoid(skill_tstat / skill_squash_k)
  skill_squash_k: 3.0  # Higher = more compression toward 0.5
  tcap: 12.0  # Clamp t-stat to [-tcap, tcap] to prevent extreme values
  se_floor: 1e-6  # Minimum SE to prevent division by zero
  
  # Stability normalization (SE-based, not std-based for cross-family comparability)
  # stability = 1 - clamp(se / se_ref, 0, 1)
  se_ref: 0.02  # Reference SE for normalization
  se_ref_by_task:
    regression: 0.02
    binary_classification: 0.015
    multiclass_classification: 0.02
  
  # Invalid slice filtering
  min_samples_per_slice: 10  # Minimum samples per slice (timestamp or symbol)
  
  # Component weights (for quality = w_cov * coverage + w_stab * stability)
  # Composite form: skill * quality (multiplicative, not additive)
  weights:
    w_cov: 0.3  # Coverage weight
    w_stab: 0.7  # Stability weight
  
  # Composite form: skill * quality (prevents no-skill targets from ranking high)
  composite_form: "skill_times_quality_v1"
  
  # Primary metric by task type (for t-stat computation)
  # Both are centered at null baseline ≈ 0
  primary_metric_by_type:
    regression: "spearman_ic"  # Null baseline ≈ 0
    classification: "auc_excess"  # Null baseline ≈ 0 (AUC - 0.5)
  
  # Model bonus (multiplicative boost for model agreement)
  model_bonus:
    enabled: true
    max_bonus: 0.10    # Maximum 10% boost
    per_model: 0.02    # 2% per model
