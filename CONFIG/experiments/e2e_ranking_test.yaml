# E2E Ranking Test Configuration
# Quick test configuration for end-to-end ranking pipeline

experiment:
  name: e2e_ranking_test
  description: "E2E test: 5 symbols, 23 targets, 50 features, reduced data limits"

data:
  data_dir: data/data_labeled/interval=5m
  symbols: [AAPL, MSFT, GOOGL, TSLA, NVDA]
  interval: 5m
  max_samples_per_symbol: 5000  # Reduced for faster testing
  max_rows_per_symbol: 5000  # Reduced for faster testing
  max_rows_train: 10000  # Reduced for faster testing
  min_cs: 3  # Reduced for faster testing

# Intelligent training settings
intelligent_training:
  auto_targets: true
  top_n_targets: 23
  max_targets_to_evaluate: 23  # Limit evaluation for faster testing
  auto_features: true
  top_m_features: 50
  strategy: single_task
  run_leakage_diagnostics: false

# Feature selection model families
feature_selection:
  model_families:
    - lightgbm
    - xgboost
    - random_forest
    - catboost
    - neural_network
    - lasso
    - mutual_information
    - univariate_selection

# Training model families (same as feature selection for consistency)
training:
  model_families:
    - lightgbm
    - xgboost
    - random_forest
    - catboost
    - neural_network
    - lasso
    - mutual_information
    - univariate_selection

# Decision configuration (SST: all values config-driven)
decisions:
  # Application mode: "off" (assist mode only), "dry_run" (show patch), "apply" (auto-apply)
  apply_mode: "dry_run"  # Test with dry_run first
  
  # Minimum decision level to apply (0=no action, 1=warning, 2=recommendation, 3=action)
  min_level_to_apply: 2
  
  # Bayesian patch policy (Thompson sampling over discrete patch templates)
  use_bayesian: true  # Enable for testing
  bayesian:
    # Minimum runs before recommending patches (reduced for testing)
    min_runs_for_learning: 3  # Lower threshold for faster testing
    # Minimum P(improve) to auto-apply
    p_improve_threshold: 0.8
    # Minimum expected gain to recommend
    min_expected_gain: 0.01
    # Reward metric to optimize
    reward_metric: "cs_auc"
    # Recency decay factor (higher = more weight on recent runs)
    recency_decay: 0.95
    # Decision level thresholds (all config-driven, no hardcoded values)
    level_3_threshold: 0.8   # P(improve) for auto-apply (level 3)
    level_3_gain: 0.01        # Expected gain for auto-apply (level 3)
    level_2_threshold: 0.6    # P(improve) for recommend (level 2)
    level_2_gain: 0.005       # Expected gain for recommend (level 2)
    level_1_threshold: 0.4    # P(improve) for warning (level 1)
    # Baseline window size (number of recent runs for baseline computation)
    baseline_window: 10

# Parallel execution configuration (for faster testing)
# These settings override defaults in target_configs.yaml and multi_model_feature_selection.yaml
multi_target:
  parallel_targets: true  # Enable parallel target evaluation (ProcessPoolExecutor)
  skip_on_error: true     # Continue to next target if one fails
  save_summary: true      # Save multi_target_summary.json

# Feature selection parallel execution
multi_model_feature_selection:
  parallel_symbols: true  # Enable parallel symbol processing (ProcessPoolExecutor)

# Threading/parallel worker configuration
# These override threading_config.yaml settings
threading:
  parallel:
    # Max workers for ProcessPoolExecutor (CPU-bound tasks like target evaluation)
    # Set to 4 for testing to balance speed vs system load
    max_workers_process: 4  # Conservative for testing (null = auto-detect)
    # Max workers for ThreadPoolExecutor (I/O-bound tasks)
    max_workers_thread: 4   # Conservative for testing (null = auto-detect)
    # Master switch for parallel execution
    enabled: true
