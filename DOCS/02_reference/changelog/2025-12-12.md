# Changelog â€” 2025-12-12

**Trend Analysis System Extension (Feature Selection), Cohort-Aware Reproducibility System, RESULTS Directory Organization, Integrated Backups, Enhanced Metadata**

For a quick overview, see the [root changelog](../../../../CHANGELOG.md).  
For other dates, see the [changelog index](README.md).

---

## Added

### Trend Analysis System Extension

**Feature Selection Integration**
- **Enhancement**: Extended trend analysis system to feature selection (single symbol + aggregated) and cross-sectional feature ranking
- **Coverage**: Trend analysis now integrated into:
  - Target Ranking (`TRAINING/ranking/predictability/model_evaluation.py`)
  - Feature Selection - Single symbol + aggregated (`TRAINING/ranking/feature_selector.py`)
  - Cross-Sectional Feature Ranking (`TRAINING/ranking/cross_sectional_feature_ranker.py`)
- **API**: All stages use the same `log_run()` API with `RunContext` and include trend analysis automatically
- **Metrics**: Tracks `n_selected`, `n_features_selected`, `mean_consensus`, `std_consensus` for feature selection
- **CS Metrics**: Tracks `cs_importance_score`, `n_features_evaluated` for cross-sectional ranking
- **Metadata**: Trend metadata stored in `metadata.json` (same format as target ranking)
- **Fallback**: Gracefully falls back to legacy `log_comparison()` API if `RunContext` unavailable
- **Files**: 
  - `TRAINING/ranking/feature_selector.py` - Updated to use `log_run()` API with trend analysis
  - `TRAINING/ranking/cross_sectional_feature_ranker.py` - Added reproducibility tracking with trend analysis

### Files Modified

#### Feature Selection
- `TRAINING/ranking/feature_selector.py`
  - Updated reproducibility tracking to use new `log_run()` API with `RunContext`
  - Integrated trend analysis (same infrastructure as target ranking)
  - Falls back to legacy `log_comparison()` API if `RunContext` unavailable
  - Tracks metrics: `n_selected`, `n_features_selected`, `mean_consensus`, `std_consensus`

#### Cross-Sectional Feature Ranking
- `TRAINING/ranking/cross_sectional_feature_ranker.py`
  - Added `output_dir` parameter to `compute_cross_sectional_importance()`
  - Integrated reproducibility tracking with `log_run()` API and trend analysis
  - Tracks CS-specific metrics: `cs_importance_score`, `n_features_evaluated`
  - Passes `output_dir` from `feature_selector.py` for tracking

### Features

- **Trend Analysis**: Both single-symbol and cross-sectional feature selection now compute trends automatically
- **Metadata Storage**: Trend metadata stored in `metadata.json` (same format as target ranking)
- **Skip Logging**: Explicit skip reasons when insufficient runs (no silent failures)
- **Audit Reports**: Audit violations/warnings logged for feature selection runs
- **Graceful Fallback**: Falls back to legacy API if `RunContext` unavailable

### Coverage

Trend analysis is now integrated into:
- âœ… Target Ranking (`TRAINING/ranking/predictability/model_evaluation.py`)
- âœ… Feature Selection - Single symbol + aggregated (`TRAINING/ranking/feature_selector.py`)
- âœ… Cross-Sectional Feature Ranking (`TRAINING/ranking/cross_sectional_feature_ranker.py`)

All stages use the same `log_run()` API with `RunContext` and include trend analysis automatically.

### Documentation

- Updated `CHANGELOG.md` with Trend Analysis System highlight
- Updated `DOCS/03_technical/implementation/TREND_ANALYZER_VERIFICATION.md` to include feature selection coverage
- Updated `DOCS/INDEX.md` with trend analyzer verification guide reference

### Testing

To verify:
1. Run feature selection multiple times (same target, same cohort)
2. Check logs for trend messages: `ðŸ“ˆ Trend (n_selected): slope=.../day`
3. Check `metadata.json` for `trend` sections
4. Verify `TREND_REPORT.json` includes feature selection series

### Related

- See [Trend Analyzer Verification Guide](../03_technical/implementation/TREND_ANALYZER_VERIFICATION.md)
- See [Cohort-Aware Reproducibility Guide](../03_technical/implementation/COHORT_AWARE_REPRODUCIBILITY.md)
